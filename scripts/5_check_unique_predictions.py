import argparse
import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt
import numpy as np

def _process_row(row: pd.Series):
    label = row.label
    row.drop('label', inplace=True)
    return row.name, list(row[row == label].index)


def evaluate_preds(df: pd.DataFrame, n_tools: int, exclude_tools: list, just_deleterious: bool):
    
    if just_deleterious:
        df = df[df.label == True].copy()

    df['to_idx'] = df.chr.astype(str) + "_" + df.pos.astype(str) + "_" + df.ref + "_" + df.alt
    df = df.set_index('to_idx')
    
    correct_preds = {v[0]: v[1] for v in df.apply(_process_row, axis=1).to_list()}

    c_hardest_variants = Counter()
    c_tools = Counter()
    n_variants = 0
    v_ids = []
    for v_id, correct_preds in correct_preds.items():
        
        if exclude_tools and any([x in correct_preds for x in exclude_tools]):
            continue
        else:
            v_ids.append(v_id)
            n_variants += 1
            
        for tool in correct_preds:
            c_tools[tool] += 1
            if len(correct_preds) <= n_tools:
                c_hardest_variants[tool] += 1    
    
    return c_hardest_variants, c_tools, n_variants, v_ids


def plot_counts(counter, available_tools, exclude_tools, n_variants, just_deleterious):

    for tool in available_tools:
        if tool not in counter.keys() and tool not in exclude_tools:
            counter[tool] = 0
    
    counter = dict(counter.most_common()[::-1])
    keys = counter.keys()
    y_pos = np.arange(len(keys))
    counts = [counter[k] for k in keys]
        
    plt.rcParams['figure.figsize'] = (6, 6)
    plt.barh(y_pos, counts, align='center', alpha=0.6, edgecolor='k')
    plt.yticks(y_pos, keys)

    if just_deleterious:
        plt.xlabel('Number of splicing-altering variants correctly predicted')
    else:
         plt.xlabel('Number of variants correctly predicted')
         
    if exclude_tools:
        plt.title('{} variants not predicted by "{}"'.format(n_variants, ';'.join(exclude_tools)))
        plt.xticks(ticks=np.arange(0,max(counts) + 1), labels=np.arange(0,max(counts) + 1))
    #plt.xlabel('Number of variants correctly predicted by few tools (< {})'.format(n_tools))
    plt.tight_layout()
    plt.savefig('test.pdf')
    
def main():
    parser = argparse.ArgumentParser(add_help=True)
    parser.add_argument('--preds_file', metavar="", required=True, help='File with predictions generated by VETA.')
    parser.add_argument('--exclude_tools', nargs="+", help='Take only into account variants not correctly predicted by these tools')
    parser.add_argument('--just_deleterious', action='store_true', help='Whether to take into account deleterious variants only')
    parser.add_argument('--number', metavar="", type=int, default=5, help='Number of tools with correct predictions to consider the variant as an "unique" example. Default:5')
    args = parser.parse_args()
    
    df = pd.read_csv(args.preds_file, sep="\t")
    #df.drop(['chr', 'pos', 'ref', 'alt', 'SYMBOL'], axis=1, inplace=True)
    tools = [x.replace("_prediction", "") for x in df.columns if "_prediction" in x]
    new_cols = [x.replace("_prediction", "") for x in df.columns]
    df.columns = new_cols
    c_hardest_variants, c_tools, n_variants, v_ids = evaluate_preds(df, 
                                                                    n_tools=args.number, 
                                                                    exclude_tools=args.exclude_tools,
                                                                    just_deleterious=args.just_deleterious)
    
    print('\n'.join([v.split("_")[1] for v in v_ids]))

   
    plot_counts(c_tools, tools, args.exclude_tools, n_variants, just_deleterious=args.just_deleterious)
    
if __name__ == "__main__":
    main()
